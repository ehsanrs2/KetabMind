QDRANT_MODE=local
QDRANT_LOCATION=./qdrant_local
QDRANT_COLLECTION=books
# EMBED_MODEL options: mock | small | base
EMBED_MODEL=small
# LLM configuration
# LLM_BACKEND options: mock | ollama | transformers
LLM_BACKEND=mock
LLM_MODEL=mock
LLM_MAX_INPUT_TOKENS=4096
LLM_MAX_NEW_TOKENS=256
LLM_TEMPERATURE=0.2
LLM_TOP_P=0.95
# Example Ollama configuration
# OLLAMA_HOST=http://localhost:11434
# LLM_BACKEND=ollama
# LLM_MODEL=mistral:7b-instruct-q4_K_M
# Note: for GPU backend see next steps.
CHUNK_SIZE=800
CHUNK_OVERLAP=200
